---
title: "Serial Incubations Litter Breakdown - Year 2 - Cleaning and Calculations"
author: "Carolyn Cummins"
date: "10/3/2023"
output: html_document
---

This file contains the clean-up, organization, and breakdown calculations for Year 2 of the Serial Incubations litter breakdown data. Difference between this Rmd file and the Rmd file for YR1 is that I had to do some extra steps to calculate the fine mesh dry mass and AFDM because I had to add in the values for the Rhodo subsamples that we sent to Vlad for FB.

***UPDATED 19 APRIL 2022 --  had to QAQC the data and account for 1.) messed up deployments and 2.) bags with holes.

****UPDATED AGAIN 4 Mar 2023 -- final data QC -- found some additional bags with holes and decided to exclude the bags that got collected in the wrong months.

*******UPDATED 27 September 2023 for MS revision -- lines 157 and 159 now contain calculations to estimate k without taking the absolute value. This is to determine whether there are any "Weight gains" in the dataset, which would show up as positive k-values before taking the absolute value.

*********UPDATED 3 October 2023 for MS revision -- filtered the dataset to exclude weight gains (only one coarse-k was interpreted as a weight gain in the dataset, and this value was likely measurement or data recording error. This value was excluded, but this also resulted in the exclusion of NA's and "Inf" values of k from the dataset in this script. This is fine because those values get excluded anyway in the "SI_Litter_Breakdown_Analyses" file.)

set WD and packages
```{r}
library(plyr)
library(dplyr)
library(lubridate)
library(ggplot2)
```


Handling Loss - Calculations, get correction factors -- this is the same data as was used for the YR 1 calculations
```{r}
handling_loss_data <- read.csv("handling_loss_SI_03Dec2020.csv")

handling_loss_data$mass_lost_g <- ((handling_loss_data$DM_start_g)-(handling_loss_data$DM_end_g))
handling_loss_data$percent_mass_lost <- (100*(handling_loss_data$mass_lost_g/handling_loss_data$DM_start_g)) 
handling_loss_data$prop_sample_afdm <- (1-(handling_loss_data$ash_g/handling_loss_data$subsample_g))
handling_loss_data$afdm <- (handling_loss_data$prop_sample_afdm*handling_loss_data$DM_end_g)

handling_loss_data_rhodo <- handling_loss_data[which(handling_loss_data$rhodo_acer=="R"),] 
handling_loss_data_acer <- handling_loss_data[which(handling_loss_data$rhodo_acer=="A"),]

avg_handling_loss_rhodo_g <- mean(handling_loss_data_rhodo$mass_lost_g)
avg_handling_loss_acer_g <- mean(handling_loss_data_acer$mass_lost_g)

corr_factor_rhodo_afdm_start <- mean(handling_loss_data_rhodo$prop_sample_afdm)
corr_factor_acer_afdm_start <- mean(handling_loss_data_acer$prop_sample_afdm)
```


Read in the coarse mesh litter breakdown data, do calculations
```{r}
coarse_mesh_data_yr2 <- read.csv("coarse_SI_YR2_4Mar23.csv")
coarse_mesh_data_yr2 <- coarse_mesh_data_yr2 %>% mutate(date_dep=mdy(date_dep))
coarse_mesh_data_yr2 <- coarse_mesh_data_yr2 %>% mutate(date_coll=mdy(date_coll))
unique(coarse_mesh_data_yr2$stream)
#stream names look good!

coarse_mesh_data_yr2 <- coarse_mesh_data_yr2 %>% mutate(unique.id=paste(bag_ID, rhodo_acer, date_dep, date_coll, stream, sep="/"))
coarse_holes.yr2 <- coarse_mesh_data_yr2 %>% filter(hole=="hole")

#corrections based on Handling Loss
coarse_mesh_data_yr2$DM_start_handloss_g <- with(coarse_mesh_data_yr2, ifelse(rhodo_acer %in% "R",(DM_start_g-avg_handling_loss_rhodo_g), DM_start_g-avg_handling_loss_acer_g))

coarse_mesh_data_yr2$afdm_start <- with(coarse_mesh_data_yr2, ifelse(rhodo_acer %in% "R",(DM_start_handloss_g*corr_factor_rhodo_afdm_start), DM_start_handloss_g*corr_factor_acer_afdm_start))

#Get %AFDM remaining - first have to get the proportion of the sample that was AFDM, then apply this to the final dry mass, then divide this by the starting AFDM and multiply by 100
coarse_mesh_data_yr2$prop_sample_afdm <- 1-((coarse_mesh_data_yr2$tin_ash_g-coarse_mesh_data_yr2$tin_g)/(coarse_mesh_data_yr2$tin_DM_g-coarse_mesh_data_yr2$tin_g))

coarse_mesh_data_yr2$afdm_final <- coarse_mesh_data_yr2$prop_sample_afdm*coarse_mesh_data_yr2$DM_end_g

coarse_mesh_data_yr2$percent_afdm_rem_C <- 100*(coarse_mesh_data_yr2$afdm_final/coarse_mesh_data_yr2$afdm_start)

coarse_mesh_data_yr2$bag_n <- substring(coarse_mesh_data_yr2$bag_ID,2,5) #this is so I can merge coarse and fine by bag #

#remove bags with holes from the df
coarse_mesh_data_yr2 <- coarse_mesh_data_yr2[!(coarse_mesh_data_yr2$hole=="hole"),]
#880 -> 869 -- additional 6 bags removed after final QC

#remove bags collected in the wrong months -- these have "QC" in the QC column
coarse_mesh_data_yr2 <- coarse_mesh_data_yr2[!(coarse_mesh_data_yr2$QC=="QC"),]
#869 -> 861 as expected

```


Read in the fine mesh litter breakdown data, add some calculations, clean
```{r}
fine_mesh_data_yr2 <- read.csv("fine_SI_YR2_4Mar23.csv")

fine_mesh_data_yr2 <- fine_mesh_data_yr2 %>% mutate(date_dep=mdy(date_dep))
fine_mesh_data_yr2 <- fine_mesh_data_yr2 %>% mutate(date_coll=mdy(date_coll))
unique(fine_mesh_data_yr2$stream)
#need to change WS05 to TOWR in this df
fine_mesh_data_yr2["stream"][fine_mesh_data_yr2["stream"] == "WS05"] <- "TOWR"
unique(fine_mesh_data_yr2$stream)

fine_mesh_data_yr2 <- fine_mesh_data_yr2 %>% mutate(unique.id=paste(bag_ID, rhodo_acer, date_dep, date_coll, stream, sep="/"))
fine_holes.yr2 <- fine_mesh_data_yr2 %>% filter(hole=="hole")

fine_mesh_data_yr2$afdm_start <- with(fine_mesh_data_yr2, ifelse(rhodo_acer %in% "R",(DM_start_g*corr_factor_rhodo_afdm_start), DM_start_g*corr_factor_acer_afdm_start))


#remove bags with holes from the df
fine_mesh_data_yr2 <- fine_mesh_data_yr2[!(fine_mesh_data_yr2$hole=="hole"),]
#880 -> 868 -- additional 9 bags removed after final QC

#remove bags collected in the wrong months -- these have "QC" in the QC column
fine_mesh_data_yr2 <- fine_mesh_data_yr2[!(fine_mesh_data_yr2$QC=="QC"),]
#868 -> 861 as expected because one of the FM bags that was deployed in the wrong month had a hole.

```


Adding in the FB subsample weights for Rhodo -- in the calculations and dfs below, "leaves" refers to the leaves we dried and weighed, while "sub" refers to the subsample that we sent to Vlad
```{r}

FB_sample_weights <- read.csv("FB _SI_YR2_Cummins_sample_weights_only_11Dec2020.csv") 
unique(FB_sample_weights$stream)
#names look good

FB_sample_weights <- FB_sample_weights[-c(441),] #remove random row of NAs in the FB data
colnames(FB_sample_weights)[colnames(FB_sample_weights)=="dm_g"]<-"DM_sub_g"
FB_sample_weights <- FB_sample_weights %>% mutate(date_dep=mdy(date_dep))
FB_sample_weights <- FB_sample_weights %>% mutate(date_coll=mdy(date_coll))

#subsetting by species -- mostly just to isolate the rhodo data
fine_mesh_data_yr2_rhodo <- fine_mesh_data_yr2[which(fine_mesh_data_yr2$rhodo_acer=="R"),]
fine_mesh_data_yr2_acer <- fine_mesh_data_yr2[which(fine_mesh_data_yr2$rhodo_acer=="A"),]

#creating the dataframe where I will do the calculations to get final AFDM for the rhodo samples
rhodo_FB_calcs <- merge(fine_mesh_data_yr2_rhodo, FB_sample_weights, by = c("stream", "date_dep", "date_coll", "bag_ID"))
rhodo_FB_calcs <- rhodo_FB_calcs[order(rhodo_FB_calcs[,3]),]
rhodo_FB_calcs$DM_leaves_final <- rhodo_FB_calcs$tin_DM_g-rhodo_FB_calcs$tin_g
rhodo_FB_calcs$afdm_leaves_final <- rhodo_FB_calcs$tin_DM_g-rhodo_FB_calcs$tin_ash_g

#calculation for percent of the DM that was AFDM for the leaves we weighed in the Rosemond lab
rhodo_FB_calcs$prop_sample_afdm <- rhodo_FB_calcs$afdm_leaves_final/rhodo_FB_calcs$DM_leaves_final

#getting a column for the AFDM of the subsample based on the column created in the previous line of code ("prop_sample_AFDM")
rhodo_FB_calcs$afdm_sub_final <- rhodo_FB_calcs$DM_sub_g*rhodo_FB_calcs$prop_sample_afdm

#Get final AFDM for the rhodo FM data
rhodo_FB_calcs$afdm_final <- ifelse(is.na(rhodo_FB_calcs$afdm_sub_final), rhodo_FB_calcs$afdm_leaves_final, (rhodo_FB_calcs$afdm_sub_final+rhodo_FB_calcs$afdm_leaves_final))

#Get percent AFDM rem for the rhodo FM data
rhodo_FB_calcs$percent_afdm_rem_F <- (100*(rhodo_FB_calcs$afdm_final/rhodo_FB_calcs$afdm_start))

#subset of rhodo_FB_calcs with only the necessary data
rhodo_FB_calcs_sub <- rhodo_FB_calcs[, c("bag_ID", "rhodo_acer", "date_dep", "date_coll", "stream", "percent_afdm_rem_F")]

```


Get AFDM final and percent AFDM remaining for the Acer FM data so that I can put it back together with the rhodo data, get same subset of Acer data as Rhodo data above
```{r}

fine_mesh_data_yr2_acer$afdm_final <- fine_mesh_data_yr2_acer$tin_DM_g-fine_mesh_data_yr2_acer$tin_ash_g

fine_mesh_data_yr2_acer$percent_afdm_rem_F <- (100*(fine_mesh_data_yr2_acer$afdm_final/fine_mesh_data_yr2_acer$afdm_start))

fine_mesh_data_yr2_acer_sub <- fine_mesh_data_yr2_acer[, c("bag_ID", "rhodo_acer", "date_dep", "date_coll", "stream", "percent_afdm_rem_F")]

```


Merge acer data and rhodo data back together (fine_mesh_data_yr2_acer and rhodo_FB_calcs)
```{r}

fine_mesh_data_yr2_final <- rbind(rhodo_FB_calcs_sub, fine_mesh_data_yr2_acer_sub)
fine_mesh_data_yr2_final <- fine_mesh_data_yr2_final[order(fine_mesh_data_yr2_final[,3]),]
fine_mesh_data_yr2_final$bag_n <- substring(fine_mesh_data_yr2_final$bag_ID,2,5) #this is so I can merge coarse and fine by bag #

```


Merge coarse and fine dfs
```{r}

coarse_mesh_data_yr2_sub <- coarse_mesh_data_yr2[, c("bag_n", "rhodo_acer", "date_dep", "date_coll", "stream", "percent_afdm_rem_C")]

fine_mesh_data_yr2_sub <- fine_mesh_data_yr2_final[, c("bag_n", "rhodo_acer", "date_dep", "date_coll", "stream", "percent_afdm_rem_F")]

coarse_fine_data_yr2_all<-full_join(coarse_mesh_data_yr2_sub,fine_mesh_data_yr2_sub, by=c("bag_n","rhodo_acer", "date_dep", "date_coll", "stream"))

coarse_fine_data_yr2_all <- coarse_fine_data_yr2_all[order(coarse_fine_data_yr2_all[,3]),] 

```



```{r}

coarse_mesh_data_yr2_sub.check <- coarse_mesh_data_yr2_sub %>% mutate(unique.id=paste(bag_n, rhodo_acer, date_dep, date_coll, stream, sep="/"))
fine_mesh_data_yr2_sub.check <- fine_mesh_data_yr2_sub %>% mutate(unique.id=paste(bag_n, rhodo_acer, date_dep, date_coll, stream, sep="/"))

coarse.unique.yr2 <- coarse_mesh_data_yr2_sub.check$unique.id
fine.unique.yr2 <- fine_mesh_data_yr2_sub.check$unique.id

setdiff(coarse.unique.yr2, fine.unique.yr2)
setdiff(fine.unique.yr2, coarse.unique.yr2)

#comparing these lists to the "holes" dataframes, we can see that the only ones removed from the final joined df are the 8 bags in both coarse and fine that were deployed in the wrong year and removed. There are no overlapping bags with holes in these dfs. 880-8=872, so the joined df has the correct number of observations!


```


Add calculations to the merged dataframe
```{r}
#for some reason, I have to change everything to a character first and then to numeric for the ln_percent_afdm_rem and k calculations...
coarse_fine_data_yr2_all$percent_afdm_rem_C<-as.character(coarse_fine_data_yr2_all$percent_afdm_rem_C)
coarse_fine_data_yr2_all$percent_afdm_rem_C<-as.numeric(coarse_fine_data_yr2_all$percent_afdm_rem_C)
coarse_fine_data_yr2_all$ln_percent_afdm_rem_C<-log(coarse_fine_data_yr2_all$percent_afdm_rem_C)

coarse_fine_data_yr2_all$percent_afdm_rem_F<-as.character(coarse_fine_data_yr2_all$percent_afdm_rem_F)
coarse_fine_data_yr2_all$percent_afdm_rem_F<-as.numeric(coarse_fine_data_yr2_all$percent_afdm_rem_F)
coarse_fine_data_yr2_all$ln_percent_afdm_rem_F<-log(coarse_fine_data_yr2_all$percent_afdm_rem_F)

coarse_fine_data_yr2_all$days_in_record<-as.numeric(coarse_fine_data_yr2_all$date_coll-coarse_fine_data_yr2_all$date_dep)
coarse_fine_data_yr2_all$ln_percent_afdm_start <- log(100)

coarse_fine_data_yr2_all$k_coarse<-as.character(((coarse_fine_data_yr2_all$ln_percent_afdm_start)-(coarse_fine_data_yr2_all$ln_percent_afdm_rem_C))/(0-coarse_fine_data_yr2_all$days_in_record))

coarse_fine_data_yr2_all$k_coarse<-as.numeric(((coarse_fine_data_yr2_all$ln_percent_afdm_start)-(coarse_fine_data_yr2_all$ln_percent_afdm_rem_C))/(0-coarse_fine_data_yr2_all$days_in_record))

coarse_fine_data_yr2_all$k_fine<-as.character(((coarse_fine_data_yr2_all$ln_percent_afdm_start)-(coarse_fine_data_yr2_all$ln_percent_afdm_rem_F))/(0-coarse_fine_data_yr2_all$days_in_record))

coarse_fine_data_yr2_all$k_fine<-as.numeric(((coarse_fine_data_yr2_all$ln_percent_afdm_start)-(coarse_fine_data_yr2_all$ln_percent_afdm_rem_F))/(0-coarse_fine_data_yr2_all$days_in_record))

coarse_fine_data_yr2_all$abs_val_k_coarse<-as.character(abs(((coarse_fine_data_yr2_all$ln_percent_afdm_start)-(coarse_fine_data_yr2_all$ln_percent_afdm_rem_C))/(0-coarse_fine_data_yr2_all$days_in_record)))

coarse_fine_data_yr2_all$abs_val_k_fine<-as.character(abs(((coarse_fine_data_yr2_all$ln_percent_afdm_start)-(coarse_fine_data_yr2_all$ln_percent_afdm_rem_F))/(0-coarse_fine_data_yr2_all$days_in_record)))

coarse_fine_data_yr2_all$abs_val_k_coarse<-as.numeric(abs(((coarse_fine_data_yr2_all$ln_percent_afdm_start)-(coarse_fine_data_yr2_all$ln_percent_afdm_rem_C))/(0-coarse_fine_data_yr2_all$days_in_record)))

coarse_fine_data_yr2_all$abs_val_k_fine<-as.numeric(abs(((coarse_fine_data_yr2_all$ln_percent_afdm_start)-(coarse_fine_data_yr2_all$ln_percent_afdm_rem_F))/(0-coarse_fine_data_yr2_all$days_in_record)))

```


```{r}

#first, check what you are removing with this filter:
gains_c.2 <- coarse_fine_data_yr2_all %>% filter(k_coarse>0) #coarse "gains" = 0

gains_f.2 <- coarse_fine_data_yr2_all %>% filter(k_fine>0) #fine "gains" = 0

#so, here, we will stick with the original data moving through the rest of the scripts
```


Calculations for shredder breakdown
```{r}

coarse_fine_data_yr2_all$abs_val_k_shred<-as.numeric(coarse_fine_data_yr2_all$abs_val_k_coarse-coarse_fine_data_yr2_all$abs_val_k_fine)

```


NEW SHREDDER K CALCULATIONS - added 18 January 2022
"rate of litter fragmentation"
new_shredder_k = k_coarse - ((k_fine-k_coarse)/(ln(k_fine)-ln(k_coarse)))
```{r}

coarse_fine_data_yr2_all$new_shredder_k <- (coarse_fine_data_yr2_all$abs_val_k_coarse - ((coarse_fine_data_yr2_all$abs_val_k_fine-coarse_fine_data_yr2_all$abs_val_k_coarse)/(log(coarse_fine_data_yr2_all$abs_val_k_fine)-log(coarse_fine_data_yr2_all$abs_val_k_coarse))))

```


Compare new_shredder_k (lecerf) to coarse-fine way of measuring shredder k
```{r}

plot.compare.shredder.k.yr2 <- ggplot(coarse_fine_data_yr2_all, aes(x=abs_val_k_shred, y=new_shredder_k)) + theme_classic() + geom_point() +
  geom_smooth(method="lm")
plot.compare.shredder.k.yr2

model.compare.shredder.k.yr2 <- lm(new_shredder_k~abs_val_k_shred, data=coarse_fine_data_yr2_all)
summary(model.compare.shredder.k.yr2)
#slope = 0.6165, R^2 = 0.9977

```


```{r}

write.csv(coarse_fine_data_yr2_all, "litter_breakdown_coarse_fine_yr2_all.4Mar23.csv")

```


