---
title: "Serial Incubations Litter Breakdown - Year 1 - Cleaning and Calculations_UPD4Mar23"
author: "Carolyn Cummins"
date: "3/4/2023"
output: html_document
---

This file contains the clean-up, organization, and breakdown calculations for Year 1 of the Serial Incubations litter breakdown data.

***UPDATED 19 APRIL 2022 -- QAQC'ed the data to account for 1.) messed up deployments and 2.) bags with holes.

****UPDATED AGAIN 4 MARCH 2023 -- final data QC -- found some additional bags with holes and decided to exclude the bags that got collected in the wrong months.

set WD and packages
```{r}
library(plyr)
library(dplyr)
library(lubridate)
library(ggplot2)
```


Handling Loss - Calculations, get correction factors
```{r}
handling_loss_data <- read.csv("handling_loss_SI_03Dec2020.csv")

handling_loss_data$mass_lost_g <- ((handling_loss_data$DM_start_g)-(handling_loss_data$DM_end_g))
handling_loss_data$percent_mass_lost <- (100*(handling_loss_data$mass_lost_g/handling_loss_data$DM_start_g)) 
handling_loss_data$prop_sample_afdm <- (1-(handling_loss_data$ash_g/handling_loss_data$subsample_g))
handling_loss_data$afdm <- (handling_loss_data$prop_sample_afdm*handling_loss_data$DM_end_g)

handling_loss_data_rhodo <- handling_loss_data[which(handling_loss_data$rhodo_acer=="R"),] 
handling_loss_data_acer <- handling_loss_data[which(handling_loss_data$rhodo_acer=="A"),]

avg_handling_loss_rhodo_g <- mean(handling_loss_data_rhodo$mass_lost_g)
avg_handling_loss_acer_g <- mean(handling_loss_data_acer$mass_lost_g)

corr_factor_rhodo_afdm_start <- mean(handling_loss_data_rhodo$prop_sample_afdm)
corr_factor_acer_afdm_start <- mean(handling_loss_data_acer$prop_sample_afdm)
```


Read in the coarse mesh litter breakdown data, do calculations
```{r}
coarse_mesh_data_yr1 <- read.csv("coarse_SI_YR1_4Mar23.csv")
coarse_mesh_data_yr1 <- coarse_mesh_data_yr1 %>% mutate(date_dep=mdy(date_dep))
coarse_mesh_data_yr1 <- coarse_mesh_data_yr1 %>% mutate(date_coll=mdy(date_coll))

coarse_mesh_data_yr1 <- coarse_mesh_data_yr1 %>% mutate(unique.id=paste(bag_ID, rhodo_acer, date_dep, date_coll, stream, sep="/"))
coarse_holes <- coarse_mesh_data_yr1 %>% filter(hole=="hole")

#corrections based on Handling Loss
coarse_mesh_data_yr1$DM_start_handloss_g <- with(coarse_mesh_data_yr1, ifelse(rhodo_acer %in% "R",(DM_start_g-avg_handling_loss_rhodo_g), DM_start_g-avg_handling_loss_acer_g))

coarse_mesh_data_yr1$afdm_start <- with(coarse_mesh_data_yr1, ifelse(rhodo_acer %in% "R",(DM_start_handloss_g*corr_factor_rhodo_afdm_start), DM_start_handloss_g*corr_factor_acer_afdm_start))

#Get %AFDM remaining - first have to get the proportion of the sample that was AFDM, then apply this to the final dry mass, then divide this by the starting AFDM and multiply by 100
coarse_mesh_data_yr1$prop_sample_afdm <- 1-((coarse_mesh_data_yr1$tin_ash_g-coarse_mesh_data_yr1$tin_g)/(coarse_mesh_data_yr1$tin_DM_g-coarse_mesh_data_yr1$tin_g))

coarse_mesh_data_yr1$afdm_final <- coarse_mesh_data_yr1$prop_sample_afdm*coarse_mesh_data_yr1$DM_end_g

coarse_mesh_data_yr1$percent_afdm_rem_C <- 100*(coarse_mesh_data_yr1$afdm_final/coarse_mesh_data_yr1$afdm_start)

coarse_mesh_data_yr1$bag_n <- substring(coarse_mesh_data_yr1$bag_ID,2,5) #this is so I can merge coarse and fine by bag #

#remove bags with holes from the df
coarse_mesh_data_yr1 <- coarse_mesh_data_yr1[!(coarse_mesh_data_yr1$hole=="hole"),]
#1152 -> 1138 -- 8  more bags with holes removed based on final QC

#remove bags that were collected in the wrong month. These have a QC flag -- "QC" in the QC column
coarse_mesh_data_yr1 <- coarse_mesh_data_yr1[!(coarse_mesh_data_yr1$QC=="QC"),]
#1138->1130 as expected

```


Read in the fine mesh litter breakdown data, add calculations
```{r}

fine_mesh_data_yr1 <- read.csv("fine_SI_YR1_4Mar23.csv")

fine_mesh_data_yr1 <- fine_mesh_data_yr1 %>% mutate(date_dep=mdy(date_dep))
fine_mesh_data_yr1 <- fine_mesh_data_yr1 %>% mutate(date_coll=mdy(date_coll))

fine_mesh_data_yr1 <- fine_mesh_data_yr1 %>% mutate(unique.id=paste(bag_ID, rhodo_acer, date_dep, date_coll, stream, sep="/"))
fine_holes <- fine_mesh_data_yr1 %>% filter(hole=="hole")

fine_mesh_data_yr1$afdm_start <- with(fine_mesh_data_yr1, ifelse(rhodo_acer %in% "R",(DM_start_g*corr_factor_rhodo_afdm_start), DM_start_g*corr_factor_acer_afdm_start))

#Get %AFDM remaining - first have to get final AFDM which for fine mesh is just the final dry mass minus the ash (this is because there is no subsampling for fine mesh because we are able to put the whole sample in the tin and ash it). Then, we get the percent AFDM remaining by dividing the final AFDM by the starting AFDM and multiplying by 100
fine_mesh_data_yr1$afdm_final <- (fine_mesh_data_yr1$tin_DM_g-fine_mesh_data_yr1$tin_ash_g)

fine_mesh_data_yr1$percent_afdm_rem_F <- 100*(fine_mesh_data_yr1$afdm_final/fine_mesh_data_yr1$afdm_start)

fine_mesh_data_yr1$bag_n <- substring(fine_mesh_data_yr1$bag_ID,2,5) #this is so I can merge coarse and fine by bag #

#remove bags with holes from the df
fine_mesh_data_yr1 <- fine_mesh_data_yr1[!(fine_mesh_data_yr1$hole=="hole"),]
#1152 -> 1139 -- 3 additional bags removed based on final QC

#remove bags collected in the wrong month
fine_mesh_data_yr1 <- fine_mesh_data_yr1[!(fine_mesh_data_yr1$QC=="QC"),]
#1139 -> 1131 as expected

```


Getting dataframes ready to merge, merge coarse and fine -- the "sub" dfs only have the necessary subset of columns from the dfs above (for simplicity)
```{r}

coarse_mesh_data_yr1_sub <- coarse_mesh_data_yr1[, c("bag_n", "rhodo_acer", "date_dep", "date_coll", "stream", "percent_afdm_rem_C")]

fine_mesh_data_yr1_sub <- fine_mesh_data_yr1[, c("bag_n", "rhodo_acer", "date_dep", "date_coll", "stream", "percent_afdm_rem_F")]

coarse_fine_data_yr1_all<-full_join(coarse_mesh_data_yr1_sub,fine_mesh_data_yr1_sub,
                                           by=c("bag_n","rhodo_acer", "date_dep", "date_coll", "stream"))


coarse_fine_data_yr1_all <- coarse_fine_data_yr1_all[order(coarse_fine_data_yr1_all[,3]),] 

```


Checking that the joined df has the right number of observations
```{r}

coarse_mesh_data_yr1_sub.check <- coarse_mesh_data_yr1_sub %>% mutate(unique.id=paste(bag_n, rhodo_acer, date_dep, date_coll, stream, sep="/"))
fine_mesh_data_yr1_sub.check <- fine_mesh_data_yr1_sub %>% mutate(unique.id=paste(bag_n, rhodo_acer, date_dep, date_coll, stream, sep="/"))

coarse.unique.1 <- coarse_mesh_data_yr1_sub.check$unique.id
fine.unique.1 <- fine_mesh_data_yr1_sub.check$unique.id

setdiff(coarse.unique.1, fine.unique.1)
setdiff(fine.unique.1, coarse.unique.1)

#comparing these lists to the "holes" dataframes, we can see that the only ones removed from the final joined df are 2 bag numbers for which both coarse and fine had holes, plus the 8 bags in both coarse and fine that were deployed in the wrong year and removed. 1152-2-8=1142, so the joined df has the correct number of observations!

```



Add calculations to the merged dataframe
```{r}

coarse_fine_data_yr1_all$percent_afdm_rem_C<-as.character(coarse_fine_data_yr1_all$percent_afdm_rem_C)
coarse_fine_data_yr1_all$percent_afdm_rem_C<-as.numeric(coarse_fine_data_yr1_all$percent_afdm_rem_C)
coarse_fine_data_yr1_all$ln_percent_afdm_rem_C<-log(coarse_fine_data_yr1_all$percent_afdm_rem_C)

coarse_fine_data_yr1_all$percent_afdm_rem_F<-as.character(coarse_fine_data_yr1_all$percent_afdm_rem_F)
coarse_fine_data_yr1_all$percent_afdm_rem_F<-as.numeric(coarse_fine_data_yr1_all$percent_afdm_rem_F)
coarse_fine_data_yr1_all$ln_percent_afdm_rem_F<-log(coarse_fine_data_yr1_all$percent_afdm_rem_F)

coarse_fine_data_yr1_all$days_in_record<-as.numeric(coarse_fine_data_yr1_all$date_coll-coarse_fine_data_yr1_all$date_dep)
coarse_fine_data_yr1_all$ln_percent_afdm_start <- log(100)

#for some reason, I have to change everything to a character first and then to numeric for the k calculations...
coarse_fine_data_yr1_all$abs_val_k_coarse<-as.character(abs(((coarse_fine_data_yr1_all$ln_percent_afdm_start)-(coarse_fine_data_yr1_all$ln_percent_afdm_rem_C))/(0-coarse_fine_data_yr1_all$days_in_record)))

coarse_fine_data_yr1_all$abs_val_k_fine<-as.character(abs(((coarse_fine_data_yr1_all$ln_percent_afdm_start)-(coarse_fine_data_yr1_all$ln_percent_afdm_rem_F))/(0-coarse_fine_data_yr1_all$days_in_record)))

coarse_fine_data_yr1_all$abs_val_k_coarse<-as.numeric(abs(((coarse_fine_data_yr1_all$ln_percent_afdm_start)-(coarse_fine_data_yr1_all$ln_percent_afdm_rem_C))/(0-coarse_fine_data_yr1_all$days_in_record)))

coarse_fine_data_yr1_all$abs_val_k_fine<-as.numeric(abs(((coarse_fine_data_yr1_all$ln_percent_afdm_start)-(coarse_fine_data_yr1_all$ln_percent_afdm_rem_F))/(0-coarse_fine_data_yr1_all$days_in_record)))

```


Calculations for shredder breakdown
```{r}

coarse_fine_data_yr1_all$abs_val_k_shred<-as.numeric(coarse_fine_data_yr1_all$abs_val_k_coarse-coarse_fine_data_yr1_all$abs_val_k_fine)

```


Lecerf et al. shredder k calculations - added 18 January 2022
"rate of litter fragmentation"
new_shredder_k = k_coarse - ((k_fine-k_coarse)/(ln(k_fine)-ln(k_coarse)))
```{r}

coarse_fine_data_yr1_all$new_shredder_k <- (coarse_fine_data_yr1_all$abs_val_k_coarse - ((coarse_fine_data_yr1_all$abs_val_k_fine-coarse_fine_data_yr1_all$abs_val_k_coarse)/(log(coarse_fine_data_yr1_all$abs_val_k_fine)-log(coarse_fine_data_yr1_all$abs_val_k_coarse))))

```


Compare new_shredder_k (lecerf) to coarse-fine way of measuring shredder k
```{r}

plot.compare.shredder.k.yr1 <- ggplot(coarse_fine_data_yr1_all, aes(x=abs_val_k_shred, y=new_shredder_k)) + theme_classic() + geom_point() +
  geom_smooth(method="lm")
plot.compare.shredder.k.yr1

model.compare.shredder.k.yr1 <- lm(new_shredder_k~abs_val_k_shred, data=coarse_fine_data_yr1_all)
summary(model.compare.shredder.k.yr1)
#slope = 0.6065, R^2 = 0.9964

```



```{r}

write.csv(coarse_fine_data_yr1_all, "litter_breakdown_coarse_fine_yr1_all.4Mar23.csv")

```


